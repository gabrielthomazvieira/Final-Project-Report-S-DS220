---
title: "S&DS 220 Final Project Report"
author: "Gabriel Thomas Vieira, Pranava Dhar, Adin Ring"
date: "5/4/2022"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo   =FALSE,      ## show or suppress the code
                      include=TRUE ,      ## show or suppress the output
                      message=FALSE,      ## omit messages generated by code
                      warning=FALSE,      ## omit warnings generated by code
                      comment=NA,         ## removes the ## from in front of outputs
                      fig.align="center", ## centers all figures
                      fig.height = 5,     ## set the default height
                      fig.weight = 5      ## set the default width
                      )
library(tidyverse)
library(GGally)
```

## Introduction 
Using data from Basketball-Reference (https://www.basketball-reference.com), we created a linear regression model to predict a team's points scored given the team, its opponent, the stadium’s attendance, the number of rest days between games, and whether it is a home or away game. We then produced power rankings of different teams based on our model’s coefficients for offensive/defensive ratings. We asked whether it was possible to predict outcomes of games (for example, the ongoing playoff series) using the above variables. Our model uses the “Schedule and Results” data for only the past 3 seasons because rosters now are significantly different from a couple of years ago; thus, using data from many years ago could lead to an inaccurate depiction of today’s teams. For example, the Rockets were the best team in the Western Conference four years ago but lost 75% of their games this season.

After constructing our linear model, we used it to predict points scored for each game, and then compared those predictions to the actual results of the games. We found that the differences between them (the residuals) were normally distributed, with an average of 0 and a standard deviation of about 12 points. That means that more than half of our predictions (about 60%) were within 10 points of the actual score. Even though our model had a relatively low adjusted $R^2$ value, we found that the model was fairly effective at ranking teams offensively and defensively and predicting outcomes.

### Data Cleaning

The code to scrape NBA Game data from Basketball Reference was adopted from <https://www.r-bloggers.com/2018/12/scraping-nba-game-data-from-basketball-reference-com/.> We modified the script to use it for the seasons from 2019 to 2022. The process involved changing the monthList for certain seasons, as 2020 and 2021 had unusual timelines

To clean the data and prepare for modelling, we separate each game into 2 rows: one for the home team and one for the away team. We also calculate an attendance percentage to use instead of the raw attendance data to account for differently-sized stadiums. Finally, we calculate the days rest since the last game each team has played, and then produce a rest differential between the teams in each match-up. When calculating rest, we replace rest times longer than 10 days (i.e. between seasons) with 10, assuming that rest longer than 10 days will not appreciably affect game results. This is done for every game in the 2019-2020 and 2020-2021 seasons, and all games up to present in the 2021-2022 season.

### Data Visualization

With our data properly cleaned, we can now explore any interesting relationships in our data. First, we'll use the `ggtext` package to add team logos to our plots to make it easier to distinguish between teams.
```{r}
# read in data
d1 = read.csv('4.27.2022_cleaned_data.csv')
```

```{r}
labels <- c(
  Atlanta.Hawks = "<img src = 'teams_logos/hawks.png' width = '18' /><br>Atlanta.Hawks",
  Boston.Celtics = "<img src = 'teams_logos/celtics.png' width = '18' /><br>oston.Celtics",
  Brooklyn.Nets = "<img src = 'teams_logos/nets.png' width = '18' /><br>Brooklyn.Nets",
  Charlotte.Hornets = "<img src = 'teams_logos/hornets.png' width = '18' /><br>Charlotte.Hornets",
  Chicago.Bulls = "<img src = 'teams_logos/bulls.png' width = '18' /><br>Chicago.Bulls",
  Cleveland.Cavaliers = "<img src = 'teams_logos/cavaliers.png' width = '18' /><br>Cleveland.Cavaliers",
  Dallas.Mavericks = "<img src = 'teams_logos/mavericks.png' width = '18' /><br>Dallas.Mavericks",
  Denver.Nuggets = "<img src = 'teams_logos/nuggets.png' width = '18' /><br>Denver.Nuggets",
  Detroit.Pistons = "<img src = 'teams_logos/pistons.png' width = '18' /><br>Detriot.Pistons",
  Golden.State.Warriors = "<img src = 'teams_logos/warriors.png' width = '18' /><br>Golden.State.Warriors",
  Houston.Rockets = "<img src = 'teams_logos/rockets.png' width = '18' /><br>Houston.Rockets",
  Indiana.Pacers = "<img src = 'teams_logos/pacers.png' width = '18' /><br>Indiana.Pacers",
  Los.Angeles.Clippers = "<img src = 'teams_logos/clippers.png' width = '18' /><br>Los.Angeles.Clippers",
  Los.Angeles.Lakers = "<img src = 'teams_logos/lakers.png' width = '18' /><br>Los.Angeles.Lakers",
  Memphis.Grizzlies = "<img src = 'teams_logos/grizzlies.png' width = '18' /><br>Memphis.Grizzlies",
  Miami.Heat = "<img src = 'teams_logos/heat.png' width = '18' /><br>Miami.Heat",
  Milwaukee.Bucks = "<img src = 'teams_logos/bucks.png' width = '18' /><br>Milwaukee.Bucks",
  Minnesota.Timberwolves = "<img src = 'teams_logos/timberwolves.png' width = '18' /><br>Minnesota.Timberwolves",
  New.Orleans.Pelicans = "<img src = 'teams_logos/pelicans.png' width = '18' /><br>New.Orleans.Pelicans",
  New.York.Knicks = "<img src = 'teams_logos/knicks.png' width = '18' /><br>New.York.Knicks",
  Oklahoma.City.Thunder = "<img src = 'teams_logos/thunder.png' width = '18' /><br>Oklahoma.City.Thunder",
  Orlando.Magic = "<img src = 'teams_logos/magic.png' width = '18' /><br>Orlando.Magic",
  Philadelphia.76ers = "<img src = 'teams_logos/76ers.png' width = '18' /><br>Philadelphia.76ers",
  Phoenix.Suns = "<img src = 'teams_logos/suns.png' width = '18' /><br>Phoenix.Suns",
  Portland.Trail.Blazers = "<img src = 'teams_logos/blazers.png' width = '18' /><br>Portland.Trail.Blazers",
  Sacramento.Kings = "<img src = 'teams_logos/kings.png' width = '18' /><br>Sacramento.Kings",
  San.Antonio.Spurs = "<img src = 'teams_logos/spurs.png' width = '18' /><br>San.Antonio.Spurs",
  Toronto.Raptors = "<img src = 'teams_logos/raptors.png' width = '18' /><br>Toronto.Raptors",
  Utah.Jazz = "<img src = 'teams_logos/jazz.png' width = '18' /><br>Utah.Jazz",
  Washington.Wizards = "<img src = 'teams_logos/wizards.png' width = '18' /><br>Washington.Wizards")
```

We will start by plotting a simple histogram of all team's points to get a better idea of the data we are dealing with.

```{r}
hist(d1$team_pts)
mean(d1$team_pts, na.rm=TRUE)
sd(d1$team_pts, na.rm=TRUE)
```

Team's points appear to be approximately normally distributed, with mean 111.29 and standard deviation 12.51. This is a great sign given our large sample and it is what we would expect from the Central Limit Theorem. Now, what about individual teams? Do any teams stand out from the rest in terms of scoring? Which teams are the least consistent? Let's see which teams have the highest points per game average:

```{r}
by_team <- d1 %>% 
  group_by(team_name) %>%
  summarise(mean_pts=mean(team_pts, na.rm=TRUE),
            st_dev=sd(team_pts, na.rm=TRUE),
            opp_pts=mean(opponent_pts, na.rm=TRUE)) %>% 
  arrange(desc(mean_pts))
  
head(by_team)

by_team <- by_team %>% 
  arrange(desc(st_dev))

head(by_team)
```

As we can see, the Milwaukee Bucks have the highest points per game average over the past three seasons, followed by the Phoenix Suns, Memphis Grizzlies, Brooklyn Nets, Minnesota Timberwolves, and the Utah Jazz. We might expect these teams to have the best offensive ratings in the league in our model. We can also see that the Los Angeles Clippers had the highest standard deviation among all teams, followed by the Wizards, Rockets, Hornets, Celtics, and Trail Blazers. Some of these teams are known to be inconsistent between games (e.g., Los Angeles Clippers), specially during playoffs, and others went through massive trades (e.g., Houston Rockets). These high standard deviations help us understand these nuances. This high inconsistency is expected to hurt these teams' standings in the power ranking.

We can also follow the same procedure for `opponent_pts`, which will allow us to understand each teams' defensive abilities. 

```{r}
by_team <- by_team %>% 
  arrange(opp_pts)

head(by_team)

by_team <- by_team %>% 
  arrange(desc(opp_pts))

head(by_team)
```

As we can see, the Boston Celtics have the lowest opponent points per game average over the past three seasons, followed by the Heat, Knicks, 76ers, Raptos, and Jazz. We might expect these teams to have the best defeensive ratings in the league in our model. Conversely, the Washington Wizards had the highest opponent points per game average over the past three seasons.

Now, let's try looking at some other variables. We usually hear about how playing at home gives the home team an advantage. We can plot the difference between points scored at home and away on average to see how these vary among teams and if that's the case for all of them. Positive values indicate that teams scores more at home, while negative values mean that teams score more away.

```{r}
home <- d1 %>% 
  group_by(team_name) %>% 
  filter(away0_home1==1) %>% 
  summarise(mean_home=mean(team_pts, na.rm = TRUE))

away <- d1 %>% 
  group_by(team_name) %>% 
  filter(away0_home1==0) %>% 
  summarise(mean_away=mean(team_pts, na.rm = TRUE))

mean_away_home <- merge(away,home)
mean_away_home$diff = home$mean_home - away$mean_away
mean_away_home$team_name <- make.names(mean_away_home[,1])

ggplot(mean_away_home, aes(x= reorder(team_name,diff), y=diff))+
  geom_col()+
  labs(y='Points difference between home and away games')+
  scale_x_discrete(name = NULL,
                   labels = labels) +
  theme(axis.text.x = ggtext::element_markdown(size = 0.20))
```
There appears to be a trend towards teams playing better at home, but it is not a rule across all teams. There is also a considerable variation across some teams. While a team playing better at home or away does not necessarily imply anything about it's ability, these deviations among teams show that playing at home or away might be able to influence the outcome of a game by a couple of points, which may be decisive in an tough game.

We can also plot a histogram of `rest_diff` to see if some games occur with a considerable difference between each teams' rest.

```{r}
hist(d1$rest_diff)
```
`rest_diff` seems roughly normally distributed, with not much deviation. Most games seem to be played with both teams having about the same rest time. Nonetheless, there are some variations that might show up when we create our model. We will now do the same thing for `attendance.perc`.

```{r}
hist(d1$attendance.perc)
```
Recall that all away games have `attendance.perc` set to 0, as we assume it should only matter for home games. We can see some interesting variations in our data. While some games are played in nearly full stadiums, others have less than 20% attendance. Although this histogram by itself does not tell us anything about the importance of this variable in our model, it might have potential to become an interesting predictor if these differences in attendance prove to be related to scoring.


## Modeling/Analysis

Our linear model uses the categorical variables team name, opponent name and whether or not it is a home game, along with the numerical variables differential rest and attendance to predict the points scored by a team. The attendance percentage variable is multiplied by our home/away variable with the assumption that attendance will matter more at home games than away games.

```{r, echo=TRUE}
m1 = lm(team_pts ~ team_name + opponent_name + away0_home1 + rest_diff + away0_home1*attendance.perc, data=d1)
m1
```
The coefficients here mean a variety of things. For the categorical variables of team name and opponent name, the coefficients form a power ranking. The rankings are based off of the first team alphabetically (the Atlanta Hawks) so all the team name coefficients represent the rankings of offenses with respect to the Hawks; because the Hawks offense is better than most other teams, almost all of these are negative. Oppositely, the mostly negative coefficients on opponent name mean that most teams have better defenses than Atlanta (the more negative, the more impact their defense has on lowering their opponents' score).

The coefficient on away0_home1 means that our model predicts an increase in score of about 1.69 points from away games to home games. The coefficient on rest.diff predicts an increase of about a quarter of a point for every day of rest a team has over its opponent. Finally, the coefficient on away0_home1*attendance.perc means that our model predicts an increase in score of 0.35 points from a completely empty to a completely full stadium (for home games only). However, the significance codes on these show that they are not very statistically significant predictors, and attendance in particular is very insignificant.

The adjusted $R^2$ of our model is 0.09421. The value is relatively low, but sports are very difficult to predict, so the result is not altogether that bad. The model seems appropriate for the data, since it generates an acceptable ranking of NBA offenses and defenses. The results of our model are pretty easy to explain, since our model predicts points scored and it's fairly easy to imagine how changing a variable affects the final score. The coefficients on the team categorical variables are slightly harder to understand because they are all relative to one specific team, but once centered, they provide a pretty clear and understandable ranking.


## Visualization and interpretation of the results
First let's extract the actual offensive and defensive ratings from our model coefficients.
```{r}
# extracting offensive and defensive coefficients, both of which are with reference to the Atlanta Hawks, as their name is alphabetically first in the categorical variable.
intervals = confint(m1, parm=names(m1$coefficients), level=.95)[-1,]

off_coeff = m1$coefficients[2:30]

def_coeff =  m1$coefficients[31:59]

unbalanced_deff_rankings = data.frame(names(def_coeff), as.numeric(def_coeff))

unbalanced_off_rankings = data.frame(names(off_coeff), as.numeric(off_coeff))
#adding the hawks and then finding median value to treat as center of the rankings.

unbalanced_off_rankings <- rbind(c("team_nameAtlanta Hawks", 0),unbalanced_off_rankings)

unbalanced_deff_rankings <- rbind(c("opponent_nameAtlanta Hawks", 0),unbalanced_deff_rankings)

med_off = median(as.numeric(unbalanced_off_rankings$as.numeric.off_coeff.))

med_def = median(as.numeric(unbalanced_deff_rankings$as.numeric.def_coeff.))

# calculating centered rankings and compiling into dfs
new_def_col = as.numeric(unbalanced_deff_rankings$as.numeric.def_coeff.) -  med_def

new_off_col = as.numeric(unbalanced_off_rankings$as.numeric.off_coeff.) -  med_off

balanced_off_rankings = data.frame(team = unbalanced_off_rankings$names.off_coeff., rating = new_off_col)

balanced_deff_rankings = data.frame(team = unbalanced_deff_rankings$names.def_coeff., rating = new_def_col)

# trimming categorical variable names
balanced_off_rankings$team = gsub("team_name(.+)", "\\1", balanced_off_rankings$team)

balanced_deff_rankings$team = gsub("opponent_name(.+)", "\\1", balanced_deff_rankings$team)

balanced_off_rankings = balanced_off_rankings[rev(order(new_off_col)),]
balanced_deff_rankings = balanced_deff_rankings[order(new_def_col),]

rownames(balanced_off_rankings) <- 1:30
rownames(balanced_deff_rankings) <- 1:30
```
Offensive Rankings:
```{r}
balanced_off_rankings
```
Defensive Rankings:
```{r}
balanced_deff_rankings
```
Note that a higher offensive rating means a better offensive performance, while a more negative defensive rating means a better defensive performance. Our power rankings capture the field relatively well, ranking 6 of the same teams in the top 10 offenses and 7 of the same teams in the top 10 defenses as Lineups.com official rankings. 

Here are those offensive ratings graphed:
```{r}
balanced_off_rankings$team = gsub("\\s", ".", balanced_off_rankings$team)
ggplot(balanced_off_rankings, aes(x=reorder(team, rating), y=rating))+
  geom_col()+
  scale_x_discrete(name = NULL,
                   labels = labels) +
  theme(axis.text.x = ggtext::element_markdown(size = 0.20))

```
And the defensive ratings:
```{r}
balanced_deff_rankings$team = gsub("\\s", ".", balanced_deff_rankings$team)
ggplot(balanced_deff_rankings, aes(x=rev(reorder(team, rating)), y=rating))+
  geom_col()+
  scale_x_discrete(name = NULL,
                   labels = labels) +
  theme(axis.text.x = ggtext::element_markdown(size = 0.20))

```
We can also check the effectiveness of our model by looking at the residuals, or the differences between predicted results of each game and the actual results. Here is a graph of actual scores vs. predictions. For a perfect model, the data would be completely linear (x=y) but the spread of our graph indicates the difficulty of fitting the data to a linear model. Still, the data trends towards x=y, which is a good sign.
```{r}
d1$yhat = predict(m1,d1)
ggplot(data=d1, aes(x=yhat, y=team_pts))+
  geom_point()+
  geom_smooth(method='lm')
```

Next we plot a histogram of residuals to see how often and by how much our predictions differed from the real scores.
```{r}
hist(m1$residuals)
```
We can also make another histogram of the same residuals, but now standardized:
```{r}
d1$res = d1$team_pts - d1$yhat
res = na.omit(d1$res)

d1$z = (d1$res - mean(d1$res, na.rm=TRUE))/sd(d1$res,na.rm=TRUE)

ggplot(data=d1, aes(x=res, y=..density..))+
  geom_histogram()
```
These plots look fairly close to a normal distribution. Let's plot a normal probability plot for our standardized residuals to see if that is indeed the case. If the dots follow the straight line closely, the residuals are close to normal.
```{r}
ggplot(data=d1, aes(sample=z))+
  geom_qq()+
  geom_qq_line()
```
The points distance themselves a little from the line near the upper and lower tail, but they follow it fairly closely in the middle. So it is safe to assume that the residuals are approximately normal.

## Conclusions and recommendations
Our model wasn't perfect, but the power rankings it produced were fairly successful. The high turnover of players makes comparing teams across different seasons tenuous, and so it is hard to say whether our model could be used to predict future seasons. Future work could incorporate the data into a logistic regression model to predict the probability of win vs. loss given a specific match-up, for example in the NBA finals.